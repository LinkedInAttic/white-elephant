###############################
# White Elephant Configuration
###############################

# Base path in Hadoop where files will be stored
job.root=/path/to/job/root

# Base path where Hadoop logs are stored.
logs.root=/path/to/logs/root

# How many Hadoop jobs to run concurrently.  Logs are assumed to be divided
# by day.  A Hadoop job will be created for each day to process.  These jobs
# are run concurrently to make the whole task finish faster.
job.concurrency=20

# How many days of log data to process.
num.days=100

# Always process the last n days of log data, even when processing data incrementally.
# This is in case recent log data is partial.
num.days.forced=5

# Where should parsed logs be stored.
jobs.output.path=/path/to/root/parsed-logs

# Where should parsed confs be stored
confs.output.path=/path/to/root/parsed-confs

# Where should aggregated usage data be stored
usage.output.path=/path/to/root/usage-per-hour

# Names of Hadoop clusters to process logs for.
cluster.names=dev-cluster,prod-cluster,other-cluster

#######################
# Hadoop Configuration
#######################

hadoop-conf.mapred.max.split.size=100000000
hadoop-conf.mapreduce.input.fileinputformat.split.maxsize=100000000
hadoop-conf.io.compression.codecs=org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.BZip2Codec
hadoop-conf.mapred.compress.map.output=true
hadoop-conf.mapred.map.output.compression.codec=com.hadoop.compression.lzo.LzoCodec

# TODO make sure to set your ugi
hadoop-conf.hadoop.job.ugi=username,hadoop
